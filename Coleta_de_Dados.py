import streamlit as st
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
import time
import random
import logging
from typing import Optional, List, Dict
from dataclasses import dataclass
from supabase import create_client
from bs4 import BeautifulSoup
import re

# Configura√ß√£o da p√°gina Streamlit
st.set_page_config(
    page_title="CMB - Capital",
    page_icon="üèóÔ∏è",
    layout="wide"
)

@dataclass
class ConfiguracaoScraper:
    tempo_espera: int = 8
    pausa_rolagem: int = 2
    espera_carregamento: int = 4
    url_base: str = "https://www.imovelweb.com.br/terrenos-venda-eusebio-ce.html"
    tentativas_max: int = 3

class SupabaseManager:
    def __init__(self):
        self.url = st.secrets["SUPABASE_URL"]
        self.key = st.secrets["SUPABASE_KEY"]
        self.supabase = create_client(self.url, self.key)

    def limpar_tabela(self):
        self.supabase.table('imoveisweb').delete().neq('id', 0).execute()

    def inserir_dados(self, df):
        registros = df.to_dict('records')
        self.supabase.table('imoveisweb').insert(registros).execute()

class ScraperImovelWeb:
    def __init__(self, config: ConfiguracaoScraper):
        self.config = config
        self.logger = self._configurar_logger()

    @staticmethod
    def _configurar_logger() -> logging.Logger:
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)

    def _get_random_user_agent(self):
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0 Safari/537.36'
        ]
        return random.choice(user_agents)

    def _configurar_navegador(self) -> webdriver.Chrome:
        try:
            opcoes_chrome = Options()
            opcoes_chrome.add_argument('--headless=new')
            opcoes_chrome.add_argument('--no-sandbox')
            opcoes_chrome.add_argument('--disable-dev-shm-usage')
            opcoes_chrome.add_argument('--window-size=1920,1080')
            opcoes_chrome.add_argument('--disable-blink-features=AutomationControlled')
            opcoes_chrome.add_argument('--enable-javascript')
            
            user_agent = self._get_random_user_agent()
            opcoes_chrome.add_argument(f'--user-agent={user_agent}')
            
            service = Service("/usr/bin/chromedriver")
            navegador = webdriver.Chrome(service=service, options=opcoes_chrome)
            
            return navegador
        except Exception as e:
            self.logger.error(f"Erro ao configurar navegador: {str(e)}")
            return None

    def _extrair_dados_imovel(self, html):
        """Extrai dados usando BeautifulSoup"""
        soup = BeautifulSoup(html, 'html.parser')
        
        try:
            # Identificadores de elementos baseados no teste2.py
            container = soup.find('div', {'data-qa': 'posting PROPERTY'})
            
            # Extra√ß√£o de dados com fallbacks
            card_id = container.get('data-id', 'N√£o identificado')
            
            # Pre√ßo
            preco_elem = container.find('div', {'data-qa': 'POSTING_CARD_PRICE'})
            preco = preco_elem.text.strip() if preco_elem else "0"
            preco = self._converter_preco(preco)
            
            # Endere√ßo
            endereco_elem = container.find('div', class_='postingLocations-module__location-address__k8Ip7')
            endereco = endereco_elem.text.strip() if endereco_elem else "Endere√ßo n√£o dispon√≠vel"
            
            # Localidade
            localidade_elem = container.find('h2', {'data-qa': 'POSTING_CARD_LOCATION'})
            localidade = localidade_elem.text.strip() if localidade_elem else "Localidade n√£o dispon√≠vel"
            
            # √Årea
            area_elem = container.find('span', class_='postingMainFeatures-module__posting-main-features-span__ror2o')
            area = area_elem.text.strip() if area_elem else "0"
            area = self._converter_area(area)
            
            # Link
            link_elem = container.find('a', {'data-to-posting': True})
            link = f"https://www.imovelweb.com.br{link_elem.get('data-to-posting')}" if link_elem else ""
            
            return {
                'cardID': card_id,
                'endereco': endereco,
                'localidade': localidade,
                'area_m2': area,
                'preco_real': preco,
                'link': link
            }
        
        except Exception as e:
            self.logger.error(f"Erro ao extrair dados: {str(e)}")
            return None
    
    def _converter_preco(self, valor):
        """Converte string de pre√ßo para float"""
        try:
            if isinstance(valor, str):
                # Remove 'R$ ' e converte para float
                valor_limpo = valor.replace('R$ ', '').replace('.', '').replace(',', '.')
                return float(valor_limpo)
            return float(valor)
        except:
            return 0.0
    
    def _converter_area(self, valor):
        """Extrai o n√∫mero da string de √°rea e converte para float"""
        try:
            if isinstance(valor, str):
                match = re.search(r'(\d+)', valor)
                if match:
                    return float(match.group(1))
            return float(valor)
        except:
            return 0.0

    def _encontrar_botao_proxima(self, navegador: webdriver.Chrome) -> Optional[webdriver.remote.webelement.WebElement]:
        try:
            return navegador.find_element(By.CSS_SELECTOR, 'a[title="Pr√≥xima"]')
        except:
            return None

    def coletar_dados(self, num_paginas: int = 9) -> Optional[pd.DataFrame]:
        navegador = None
        todos_dados: List[Dict] = []
        progresso = st.progress(0)
        status = st.empty()
    
        try:
            self.logger.info("Iniciando coleta de dados...")
            navegador = self._configurar_navegador()
            if navegador is None:
                st.error("N√£o foi poss√≠vel inicializar o navegador")
                return None
    
            navegador.get(self.config.url_base)
            self.logger.info("Navegador acessou a URL com sucesso")
            
            for pagina in range(1, num_paginas + 1):
                try:
                    status.text(f"‚è≥ Processando p√°gina {pagina}/{num_paginas}")
                    progresso.progress(pagina / num_paginas)
                    self.logger.info(f"Processando p√°gina {pagina}")
                    
                    time.sleep(random.uniform(2, 4))
    
                    # Rolar a p√°gina para carregar elementos
                    for i in range(10):
                        navegador.execute_script(f"window.scrollTo(0, {i * 300});")
                        time.sleep(0.3)
    
                    # Encontrar todos os cards de im√≥veis
                    imoveis = navegador.find_elements(By.CSS_SELECTOR, 'div[data-qa="posting PROPERTY"]')
                    
                    if not imoveis:
                        self.logger.warning(f"Sem im√≥veis na p√°gina {pagina}")
                        break
    
                    # Extrair dados de cada im√≥vel
                    for imovel in imoveis:
                        html = imovel.get_attribute('outerHTML')
                        if dados := self._extrair_dados_imovel(html):
                            todos_dados.append(dados)
    
                    # Navegar para pr√≥xima p√°gina
                    if pagina < num_paginas:
                        botao_proxima = self._encontrar_botao_proxima(navegador)
                        if not botao_proxima:
                            break
                        navegador.execute_script("arguments[0].click();", botao_proxima)
                        time.sleep(2)
    
                except Exception as e:
                    self.logger.error(f"Erro na p√°gina {pagina}: {str(e)}")
                    continue
    
            return pd.DataFrame(todos_dados) if todos_dados else None
    
        except Exception as e:
            self.logger.error(f"Erro cr√≠tico: {str(e)}")
            st.error(f"Erro durante a coleta: {str(e)}")
            return None
    
        finally:
            if navegador:
                try:
                    navegador.quit()
                except Exception as e:
                    self.logger.error(f"Erro ao fechar navegador: {str(e)}")

def main():
    try:
        # T√≠tulos e descri√ß√£o
        st.title("üèóÔ∏è Coleta Informa√ß√µes Gerais Terrenos - Eus√©bio, CE")
        
        st.markdown("""
        <div style='text-align: center; padding: 1rem 0;'>
            <p style='font-size: 1.2em; color: #666;'>
                Coleta de dados de terrenos √† venda em Eus√©bio, Cear√°
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Informa√ß√µes sobre a coleta
        st.info("""
        ‚ÑπÔ∏è **Informa√ß√µes sobre a coleta:**
        - Digite o n√∫mero de p√°ginas que deseja coletar (m√°ximo 9)
        - Apenas terrenos em Eus√©bio/CE
        - Ap√≥s a coleta, voc√™ pode escolher se deseja salvar os dados no banco
        """)

        # Input para n√∫mero de p√°ginas
        num_paginas = st.number_input("N√∫mero de p√°ginas para coletar", min_value=1, max_value=9, value=5)
        
        # Separador visual
        st.markdown("<hr>", unsafe_allow_html=True)
        
        # Bot√£o centralizado
        if st.button("üöÄ Iniciar Coleta", type="primary", use_container_width=True):
            st.session_state.dados_salvos = False
            with st.spinner("Iniciando coleta de dados..."):
                config = ConfiguracaoScraper()
                scraper = ScraperImovelWeb(config)
                st.session_state.df = scraper.coletar_dados(num_paginas)
                
        # Se temos dados coletados
        if hasattr(st.session_state, 'df') and st.session_state.df is not None and not st.session_state.df.empty:
            df = st.session_state.df
            
            # M√©tricas principais
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total de Im√≥veis", len(df))
            with col2:
                preco_medio = df['preco_real'].mean()
                st.metric("Pre√ßo M√©dio", f"R$ {preco_medio:,.2f}")
            with col3:
                area_media = df['area_m2'].mean()
                st.metric("√Årea M√©dia", f"{area_media:,.2f} m¬≤")
            
            st.success("‚úÖ Dados coletados com sucesso!")
            
            # Exibi√ß√£o dos dados
            st.markdown("### üìä Dados Coletados")
            st.dataframe(
                df.style.format({
                    'preco_real': 'R$ {:,.2f}',
                    'area_m2': '{:,.2f} m¬≤'
                }),
                use_container_width=True
            )
            
            # Confirma√ß√£o para salvar no banco
            if not hasattr(st.session_state, 'dados_salvos') or not st.session_state.dados_salvos:
                st.markdown("### üíæ Salvar no Banco de Dados")
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("‚úÖ Sim, salvar dados", key='save_button', use_container_width=True):
                        try:
                            with st.spinner("üíæ Salvando dados no banco..."):
                                db = SupabaseManager()
                                db.inserir_dados(df)
                                st.session_state.dados_salvos = True
                                st.success("‚úÖ Dados salvos no banco de dados!")
                                st.balloons()
                        except Exception as e:
                            st.error(f"‚ùå Erro ao salvar no banco de dados: {str(e)}")
                
                with col2:
                    if st.button("‚ùå N√£o salvar", key='dont_save_button', use_container_width=True):
                        st.session_state.dados_salvos = True
                        st.info("üìù Dados n√£o foram salvos no banco.")
            
            # Bot√£o de download
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="üì• Baixar dados em CSV",
                data=csv,
                file_name=f'terrenos_eusebio_{datetime.now().strftime("%Y%m%d")}.csv',
                mime='text/csv',
            )
            
            if hasattr(st.session_state, 'dados_salvos') and st.session_state.dados_salvos:
                st.info("üîÑ Para iniciar uma nova coleta, atualize a p√°gina.")
                
        # Rodap√©
        st.markdown("<hr>", unsafe_allow_html=True)
        st.markdown("""
            <div style='text-align: center; padding: 1rem 0; color: #666;'>
                <p>Desenvolvido com ‚ù§Ô∏è por Rhuan Mateus - CMB Capital</p>
                <p style='font-size: 0.8em;'>√öltima atualiza√ß√£o: Janeiro 2025</p>
            </div>
        """, unsafe_allow_html=True)
        
    except Exception as e:
        st.error(f"‚ùå Erro inesperado: {str(e)}")
        st.error("Por favor, atualize a p√°gina e tente novamente.")

if __name__ == "__main__":
    main()
